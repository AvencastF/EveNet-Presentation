---
class: py-10
---

# To bring them all...

<span>Summary of EveNet achievements</span>

<v-clicks>

- Trained <span class="gradient-animated" style="font-variant: small-caps;">EveNet</span> encoder–decoder with 5 task-specific heads on <span text="[#00e5ff]">500M fast-simulated events</span>
- Tested <span class="gradient-animated" style="font-variant: small-caps;">EveNet</span> across <span text="[#00e5ff]">4 downstream tasks</span> with different detectors, kinematic regimes, pile-up simulations and <span text="[#00e5ff]">real data</span>
- Achieved promising performance with <span text="[#00e5ff]">2-stage pretraining</span>
  - Outperforms scratch and task-specific models
  - Including <span text="[#00e5ff]">tabular foundation models</span>
- The S/B analysis workflow is simplified, as pretraining removes the need for auxiliary heads and a <span text="[#00e5ff]">single classification head</span> is sufficient.
- Demonstrated <span text="[#00e5ff]">robustness to systematic variations</span>
- Achieved <span text="[#00e5ff]">fast convergence</span>
  - Up to <span text="[#00e5ff]">3× faster</span> than scratch training
- Effective in <span text="[#00e5ff]">low-statistics regimes</span>
  - Both <span text="[#00e5ff]">classification</span> and <span text="[#00e5ff]">generative tasks</span>

</v-clicks>
